#!/usr/bin/env python3

import argparse
import collections
import itertools
import os
import sys

import c

parser = argparse.ArgumentParser()
parser.add_argument('filename_schema')
parser.add_argument('filename_dictionary')
parser.add_argument('filename_header')
parser.add_argument('filename_implementation')
args = parser.parse_args()

GENERATED_NOTE = (
    '//Generated with the command\n//    {com}'
).format(com=' '.join(sys.argv))

if __name__ == '__main__':
    enums = [c.Enum('phoneme_family'), c.Enum('phoneme_genus'),
             c.Enum('phoneme')]
    pairings = tuple(collections.defaultdict(list) for _ in enums)
    with open(args.filename_schema, 'r') as f:
        for line in f:
            indentation = line.count('\t')
            name = line.strip()
            enums[indentation].append(name)
            if indentation > 0:
                j = indentation - 1
                parent = enums[j].values[-1]
                pairings[j][parent].append(name)
            if indentation == len(enums) - 1:
                pairings[-1][name].append('"{nam}"'.format(nam=name))
    classifiers = [
        c.Classifier(
            'classify_family',
            enums[1].name,
            enums[0].name,
            pairings[0],
            ),
        c.Classifier(
            'classify_genus',
            enums[2].name,
            enums[1].name,
            pairings[1],
        ),
        c.Classifier(
            'classify_phoneme',
            'char *',
            enums[2].name,
            pairings[2],
            comparer=lambda a, b: 'strcmp({a}, {b}) == 0'.format(a=a, b=b),
        )
    ]
    #Getting a bunch of constants so I don't have to both with dynamic
    #allocation in the C code.
    with open(args.filename_dictionary, 'r') as f:
        dictionary_length = 0
        max_line_length = 0
        max_word_length = 0
        max_num_phonemes = 0
        for line in filter(lambda line: not line.startswith(';;;'), f):
            dictionary_length += 1
            max_line_length = max(max_line_length, len(line))
            pieces = line.split()
            max_word_length = max(max_word_length, len(pieces[0]))
            max_num_phonemes = max(max_num_phonemes, len(pieces) - 1)
    macros = [
        c.Macro('FILENAME_DICTIONARY',
              '"{fil}"'.format(fil=args.filename_dictionary)),
        c.Macro('DICTIONARY_LENGTH', dictionary_length),
        c.Macro('MAX_LINE_LENGTH', max_line_length),
        c.Macro('MAX_WORD_LENGTH', max_word_length),
        c.Macro('MAX_NUM_PHONEMES', max_num_phonemes),
    ]
    with open(args.filename_header, 'w') as f:
        guard = c.IncludeGuard(args.filename_header)
        f.write('\n'.join(map(str, itertools.chain(
            [guard.begin()],
            [GENERATED_NOTE],
            macros,
            [c.Typedef('unsigned char', 'accent')],
            enums,
            [classifier.signature(names=False) for classifier in classifiers],
            [guard.end()],
        ))))

    with open(args.filename_implementation, 'w') as f:
        f.write('\n'.join(map(str, itertools.chain(
            [GENERATED_NOTE],
            #It would be better to get '"arpabet.h"', but it's fine.
            [c.Header(name) for name in (
                os.path.basename(args.filename_header),
                'stdio.h',
                'stdlib.h',
                'string.h',
            )],
            classifiers,
        ))))
